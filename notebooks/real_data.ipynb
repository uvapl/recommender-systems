{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07703a35-c4d9-4de0-aefc-11eae0ed9c88",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b75dc23784d20d4644b8acdd534d8fa",
     "grade": false,
     "grade_id": "cell-1c68fe4b5e309644",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# [1.3: Real Data] — Applying kNN and Evaluating on Realistic Data\n",
    "\n",
    "Until now, you have worked with a small toy dataset to learn how kNN functions and how to evaluate recommender systems.\n",
    "Now we will see how kNN performs on **more realistic data**.\n",
    "\n",
    "The dataset we use here comes from **MovieLens**, a movie recommendation platform run by the GroupLens research lab at the University of Minnesota. MovieLens datasets are widely used in research and education because they contain real user ratings and are carefully curated for experimentation.\n",
    "\n",
    "However, we are **not** using the full raw dataset. Collaborative filtering methods such as kNN are heavily influenced by **long-tail effects**: most movies receive very few ratings, and most users rate only a small number of movies. If we applied kNN directly to the full MovieLens dataset, it would perform very poorly (the algorithm simply would not have enough overlapping rating information to make reliable predictions).\n",
    "\n",
    "To reduce this issue, we limit ourselves to the **most active users** and the **most frequently rated movies**.\n",
    "The file `ratings1_18M.csv` includes only:\n",
    "\n",
    "* movies with **1000+ ratings**, and\n",
    "* users with **400+ ratings**.\n",
    "\n",
    "This gives us a much denser dataset where kNN can operate effectively.\n",
    "\n",
    "This filtering step may feel a bit **contrived**, but it is quite realistic: In industry settings, multiple algorithms are often used together, each specializing in different parts of the data. It is easy to imagine a hybrid system in which kNN is responsible only for the most common cases (popular items and highly active users), while other models handle the long tail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562aa5a3-27b5-428f-9c4d-a829d06a383c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dbea45070338e53e939c31f734c3f68",
     "grade": false,
     "grade_id": "cell-b738e820c2715b7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "### Libraries\n",
    "\n",
    "Let's start by loading the libraries we'll need by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eef3bd-3f11-4051-88b6-495b99e6a15f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68d933d8dae5fa201bee2e6c160c8d47",
     "grade": false,
     "grade_id": "cell-91deeea42471d640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pooch\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87093b59-ba80-4064-a772-d40bc3b34990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d677a98b0763d2658ddc5464b42adebd",
     "grade": false,
     "grade_id": "cell-84c3fdee4fdd4110",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Download data\n",
    "\n",
    "Now download and load the required data and helper files:\n",
    "\n",
    "* **`ratings1_18M.csv`**: the full filtered dataset (popular movies and active users)\n",
    "* **`ratings1_18M_train.csv`** and **`ratings1_18M_test.csv`**: an 80/20 train–test split of the same data\n",
    "\n",
    "These files will allow us to run kNN on a realistic dataset and evaluate its performance properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113bcee-157b-4650-bc7b-274fcdd82ba7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "367c27b4fe15052d08b3efaa7b5ce966",
     "grade": false,
     "grade_id": "cell-65dc29ea47a0c2ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_REPO = \"https://raw.githubusercontent.com/uvapl/recommender-systems/main/data/m1/\"\n",
    "\n",
    "print(\"downloading data files\")\n",
    "for fname in [\"ratings1_18M.csv\", \"ratings1_18M_train.csv\", \"ratings1_18M_test.csv\"]:\n",
    "    pooch.retrieve(url = DATA_REPO + fname, known_hash=None, fname=fname, path=\"data\", progressbar=True)\n",
    "for fname in [\"helpers_m1.py\", \"pr_curve.png\", \"tests_m1.py\"]:\n",
    "    pooch.retrieve(url = DATA_REPO + fname, known_hash=None, fname=fname, path=\".\", progressbar=True)\n",
    "print(\"done\")\n",
    "\n",
    "import helpers_m1\n",
    "import tests_m1\n",
    "\n",
    "ratings_df = pd.read_csv(\"data/ratings1_18M.csv\")[[\"userId\", \"movieId\", \"rating\"]]\n",
    "ratings_df_train = pd.read_csv(\"data/ratings1_18M_train.csv\")[[\"userId\", \"movieId\", \"rating\"]]\n",
    "ratings_df_test = pd.read_csv(\"data/ratings1_18M_test.csv\")[[\"userId\", \"movieId\", \"rating\"]]\n",
    "display(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8feb5b2-a9ef-40cc-b5a1-d522e2f41c0c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c6fedd042f8c91559c61a958d5502a3",
     "grade": false,
     "grade_id": "cell-38a51052412dbe93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# kNN (again)\n",
    "\n",
    "In this section, we shift to a more realistic prediction task. Previously, we predicted **multiple users’ ratings for a single movie**. Now we will predict ratings for **many different (user, movie)** combinations. This gives us a much clearer and more realistic picture of how kNN performs in practice.\n",
    "\n",
    "Why didn’t we do this before? This approach does *not* work smoothly with scikit-learn. A robust kNN regression implementation that handles all edge cases would take a lot of time. As this would not help your conceptual understanding, we decided to just provide you with the necessary implementation in the `helper.py` file.\n",
    "\n",
    "## Provided functions\n",
    "\n",
    "The file `helper.py` includes two key functions:\n",
    "\n",
    "* `build_utility_matrices()`\n",
    "  This computes:\n",
    "\n",
    "  * the utility matrix (pivot table with users as rows, movies as columns)\n",
    "  * its mean-centered version\n",
    "  * the average rating for each user\n",
    "\n",
    "* `predict_user_based_knn()`\n",
    "  This runs a full user-based kNN prediction procedure for all *(user, movie)* pairs in the test set.\n",
    "\n",
    "  * It returns a DataFrame containing predictions such as:\n",
    "\n",
    "  <table border=\"1\" class=\"dataframe\">\n",
    "  <thead><tr style=\"text-align: right;\"><th></th><th>userId</th><th>movieId</th><th>pred_rating</th></tr></thead>\n",
    "  <tbody>\n",
    "  <tr><th>0</th><td>198</td><td>19</td><td>2.256578</td></tr>\n",
    "  <tr><th>1</th><td>198</td><td>158</td><td>2.313034</td></tr>\n",
    "  <tr><th>2</th><td>198</td><td>165</td><td>3.498298</td></tr>\n",
    "  <tr><th>3</th><td>198</td><td>173</td><td>2.302315</td></tr>\n",
    "  <tr><th>…</th><td>…</td><td>…</td><td>…</td></tr>\n",
    "  </tbody>\n",
    "  </table>\n",
    "  \n",
    "  * This output can be compared directly to the true ratings in the test set.\n",
    "  * Note that the predicted ratings are the *actual ratings* (scale 1 - 5) and not mean-centered ratings.\n",
    "\n",
    "### Some details on the implementation\n",
    "\n",
    "You do **not** need to fully understand how the function is implemented. However, it is important to be aware that real-world data introduces many edge cases that simple kNN logic cannot handle gracefully.\n",
    "\n",
    "The prediction function is designed to ensure that:\n",
    "\n",
    "* No prediction attempt fails due to missing data.\n",
    "* Predictions are never based on zero or meaningless information.\n",
    "* Cold-start users, cold-start items, sparse neighborhoods, and degenerate similarity values are all handled safely.\n",
    "* The final output cleanly separates predictions from ground truth data.\n",
    "\n",
    "To achieve this, the function includes solutions for several common edge cases:\n",
    "\n",
    "1. **Cold-start users**\n",
    "   Users in the test set who have **no training ratings** cannot be compared to anyone.\n",
    "   Solution: Use the **global average rating**.\n",
    "\n",
    "2. **Cold-start items**\n",
    "   Movies in the test set that have **no ratings in training** cannot receive a neighborhood-based estimate.\n",
    "   Solution: Use the **user’s average rating**.\n",
    "\n",
    "3. **Neighbors who never rated the target movie**\n",
    "   Solution: These neighbors are excluded rather than treated as zeros.\n",
    "\n",
    "4. **Too few usable neighbors**\n",
    "   If hardly any neighbors have rated the target movie, similarity-based prediction becomes unreliable.\n",
    "   Solution: Fall back to the **user’s average rating**.\n",
    "\n",
    "5. **Zero similarity information**\n",
    "   If similarities sum to zero (e.g., all zeros after filtering), the model cannot get a meaningful weighted average.\n",
    "   Solution: Again revert to the **user’s average**.\n",
    "\n",
    "6. **Self-similarity**\n",
    "   kNN search often returns the user as their own closest neighbor.\n",
    "   Solution: The model explicitly removes this to avoid trivial predictions.\n",
    "\n",
    "These cases are all needed to allow kNN to work robustly on large, (potentially) sparse, real-world datasets.\n",
    "\n",
    "## Run\n",
    "\n",
    "Now run the cell below to apply kNN to the full dataset and compute the baseline.\n",
    "Note that this may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb41e66-2f02-471a-b384-27fb091fcc4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "121f3f00c2ce5357c43608d3ad31315c",
     "grade": false,
     "grade_id": "cell-88e7349c1c8ede81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "utility_train, utility_centered, user_means = helpers_m1.build_utility_matrices(ratings_df_train)\n",
    "\n",
    "ratings_df_pred = helpers_m1.predict_user_based_knn(utility_train, utility_centered, user_means, ratings_df_test, k = 20)\n",
    "ratings_df_baseline_user_mean = helpers_m1.predict_user_mean(utility_train, utility_centered, user_means, ratings_df_test)\n",
    "\n",
    "display(ratings_df_pred.head())\n",
    "display(ratings_df_baseline_user_mean.head())\n",
    "display(ratings_df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd3dc4b-f3dc-4427-b728-2e93a76584a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88971c09556efcc618462e5a045f240d",
     "grade": false,
     "grade_id": "cell-e68d96504835b194",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# MSE\n",
    "\n",
    "We now have predicted ratings from kNN as well as baseline predictions. To evaluate how well they match the true ratings in the test set, we can compute the **Mean Squared Error (MSE)**.\n",
    "\n",
    "Instead of using our own implementation, we will now use the standard `mean_squared_error` function from scikit-learn.\n",
    "Run the cell below to compute and compare the MSE values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674c819-4bd8-44c2-854c-9da3f2056413",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "025dfcff16b64a7abc70631bbb6f20c7",
     "grade": false,
     "grade_id": "cell-fd3354afebcdc875",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mse_predicted = mean_squared_error(ratings_df_test[\"rating\"], ratings_df_pred[\"pred_rating\"])\n",
    "mse_baseline = mean_squared_error(ratings_df_test[\"rating\"], ratings_df_baseline_user_mean[\"pred_rating\"])\n",
    "print(f\"MSE predicted = {mse_predicted:.3f}\")\n",
    "print(f\"MSE baseline = {mse_baseline:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e750e-d8ff-42b9-80db-ba1bc389e2fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce90742a673339147e58706424ab3848",
     "grade": false,
     "grade_id": "cell-d6240d04a09f36fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Precision and Recall\n",
    "\n",
    "To compute precision and recall, we again need to treat the problem as a **classification task**. That means we must know, for each (user, movie) pair in the **test set**, whether the user actually *liked* the movie.\n",
    "\n",
    "Unfortunately, our dataset does not contain an explicit “liked / not liked” label.\n",
    "So we will approximate it (a common practice in recommender-system evaluation). We use the **actual rating** as a proxy:\n",
    "\n",
    "* If a rating is **greater than 3.5**, we assume the user liked the movie (`True`).\n",
    "* Otherwise, we assume they did not (`False`).\n",
    "\n",
    "Run the cell below to create a `liked_test` Series with `True`/`False` values indicating whether each test-case movie was actually liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800c665-64f2-47b6-bc94-b59c1ae2f9c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c57978ca9e0ff46c5b4271da7ea050ee",
     "grade": false,
     "grade_id": "cell-2f9972ce8b4c4f3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "T = 3.5\n",
    "liked_test = ratings_df_test[\"rating\"] >= T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816be52e-8143-4b1c-ae8d-123255f81f25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ecbea5787a3f27e0735833779f75dc6",
     "grade": false,
     "grade_id": "cell-98abd6550dac524f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once we have that information, we need to convert our **predicted ratings** into **recommendation decisions**. This works the same way as before: we apply a **threshold** to determine whether a predicted rating is high enough to justify recommending the movie.\n",
    "\n",
    "This gives us a set of predicted labels (`True`/`False`) that we can directly compare to the actual `liked_test` labels when computing precision and recall.\n",
    "\n",
    "Run the cell below to generate these recommendation labels for both the kNN model and the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7e1a2-84f1-4dd8-af6d-b42e6fd21b17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c8d54123c3da99cb81c719d1e334136",
     "grade": false,
     "grade_id": "cell-7ef7e80f9078b003",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t_pred = 3.9\n",
    "\n",
    "recommendations_knn = ratings_df_pred[\"pred_rating\"] >= t_pred\n",
    "recommendations_mean = ratings_df_baseline_user_mean[\"pred_rating\"] >= t_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b2d98-5c9a-4503-8383-17b13e18794e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62776fca6be2ea05ab0d504544fa477a",
     "grade": false,
     "grade_id": "cell-f97579d9f234573a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "*2 pts.*\n",
    "\n",
    "Use the `precision_score()` and `recall_score()` functions from scikit-learn (already imported above) to compute the **precision** and **recall** for both the kNN model and the baseline.\n",
    "Use the previously computed variables:\n",
    "\n",
    "* `liked_test`\n",
    "* `recommendations_knn`\n",
    "* `recommendations_mean`\n",
    "\n",
    "Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25127570-26e0-4b6b-b75c-5ccc42184b9f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "257e533a1e54732bf8a585cff83ad3b2",
     "grade": true,
     "grade_id": "cell-ef1c31d9f5de610d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "print(f\"          |  knn | mean \")\n",
    "print(f\"precision | {precision_knn:.2f} | {precision_mean:.2f}\")\n",
    "print(f\"recall    | {recall_knn:.2f} | {recall_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35d8e5-d2c9-4a1b-ba67-62a6d9fb08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your solution\n",
    "tests_m1.real_data_01(precision_knn, precision_mean, recall_knn, recall_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f197f3-c56f-4a28-a1fb-12bf596acfdd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "772fb4936da3538e8116f57030f600db",
     "grade": false,
     "grade_id": "cell-5c44f4ec759cf716",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# F1 Score\n",
    "\n",
    "As mentioned in the previous notebook, **precision** and **recall** often behave in opposing ways. Improving one can worsen the other. For example, increasing the recommendation threshold may raise **precision** (because only highly confident recommendations are shown), but this usually lowers **recall**, since fewer potentially relevant items are included.\n",
    "  \n",
    "Because these two metrics can move in different directions, we often want a **single** score that captures both aspects of performance. A common way to do that is with the **F1 score**, defined as:\n",
    "\n",
    "$\n",
    "F_1 = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}\n",
    "{\\text{precision} + \\text{recall}}\n",
    "$\n",
    "\n",
    "The F1 score is the **harmonic mean** of precision and recall. It penalizes imbalance: The F1 score is low if either precision *or* recall is low. A model cannot achieve a high F1 score by excelling at one and ignoring the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7b1bf-6d2a-4f30-b4f9-03d80addc158",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8817cd39515fcbf263c946c89729bd60",
     "grade": false,
     "grade_id": "cell-607a295cb6bdda2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "*2 pts.*\n",
    "\n",
    "Compute the F1 score for both the kNN recommendations and mean baseline, based on the previously computed precision and recall scores. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934af848-131f-475e-b331-7b7211e9d81a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cf7b967118aee7172d1f71ab6834c0a",
     "grade": false,
     "grade_id": "cell-ce3c6c16fb562ead",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "print(f\"F1 score kNN: {f1_knn:.2f}\")\n",
    "print(f\"F1 score mean: {f1_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001739ff-b012-4152-a51f-d46114325eea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95cd365162b8afe43a0f0018124d7572",
     "grade": true,
     "grade_id": "cell-b14ede6056d30e69",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "tests_m1.real_data_02(f1_knn, f1_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b5780-8157-4c60-9277-ee61c7b9bae4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d45bc23ee133c5ec59bc760e1a357fba",
     "grade": false,
     "grade_id": "cell-f5562342fc2c8205",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Precision–Recall Curve\n",
    "\n",
    "Up to now, we have evaluated precision and recall using a single fixed threshold. But in practice, the threshold is a tunable parameter: changing it can dramatically alter the behaviour of the recommender system.\n",
    "\n",
    "If we **increase** the threshold, we become more conservative in our recommendations. Only the highest predicted ratings count as recommended. This usually **increases precision** (fewer incorrect recommendations) but **decreases recall** (we miss more potentially good recommendations).\n",
    "\n",
    "A precision–recall curve helps us understand this trade-off.\n",
    "\n",
    "A **precision–recall (PR) curve** shows how precision and recall change as we vary the classification threshold. For every possible threshold value, we:\n",
    "\n",
    "* convert predicted ratings into recommended / not recommended,\n",
    "* compute precision,\n",
    "* compute recall,\n",
    "* and plot the resulting point.\n",
    "\n",
    "Connecting all these points yields the PR curve.\n",
    "\n",
    "Ideally, if the algorithm works well, we should be able to find points on the curve where **both precision and recall are relatively high**. This would mean there exists a threshold at which the recommender system performs well on both fronts. In such cases, the PR curve will tend toward the **upper-right corner** of the plot.\n",
    "\n",
    "For example:\n",
    "\n",
    "<img src='pr_curve.png' width=\"350pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4537fb-297a-4810-acf9-3f304551a4e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2a4248c6bda09394a2fb1da3093d287",
     "grade": false,
     "grade_id": "cell-f4a0e2034df87a67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Challenge 1\n",
    "\n",
    "*6 pts.*\n",
    "\n",
    "Create **precision–recall curves** for both the **kNN algorithm** and the **baseline**.\n",
    "Vary the recommendation threshold from **1.5 to 4.5** in steps of **0.05**, and compute the **precision** and **recall** at each threshold. Store these values and use them to plot the two PR curves.\n",
    "\n",
    "Make sure that:\n",
    "\n",
    "* both curves are clearly labeled,\n",
    "* the axes are labeled,\n",
    "* and the visualization is accessible for colorblind readers (e.g., by using distinct line styles in addition to color).\n",
    "\n",
    "**You need to discuss your solution in person to receive these points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddeb7b4-16ed-4cb1-a52c-e303f4126551",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7b40564a826105694a711fdae3372dd",
     "grade": true,
     "grade_id": "cell-320c7445db08539c",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0a9eba-8a1b-48c0-b86e-56c19cfd06af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdc84cc9111d44caa395dce69212d383",
     "grade": false,
     "grade_id": "cell-91f7f70da6f3bb59",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Challenge 2\n",
    "\n",
    "*4 pts.*\n",
    "\n",
    "On both PR curves (kNN and baseline), identify and mark the point where the **F1 score** is highest. For both curves:\n",
    "\n",
    "* mark the corresponding point on the plot,\n",
    "* and display the **threshold**, **precision**, and **recall** values at which this maximum F1 score occurs.\n",
    "\n",
    "Make sure these points are clearly distinguishable on the graph.\n",
    "\n",
    "**You need to discuss your solution in person to receive these points.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bc055-e4f1-4390-8a84-4715dda98a76",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65dcac139c49bd55827f2e13720746c1",
     "grade": false,
     "grade_id": "cell-a0ef62fbdf903726",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Challenge 3\n",
    "\n",
    "*4 pts.*\n",
    "\n",
    "Create a new precision–recall curve for **only the kNN model**, but this time:\n",
    "\n",
    "* **fix the threshold at `3.1`**, and\n",
    "* **vary the value of `k`**.\n",
    "\n",
    "Determine an appropriate range of `k` values to explore (you should pick no more than about 10 values, since rerunning the kNN algorithm for each `k` is computationally expensive).\n",
    "\n",
    "For each chosen `k`:\n",
    "\n",
    "* recompute the predictions,\n",
    "* convert them into recommendations using the fixed threshold,\n",
    "* compute precision and recall,\n",
    "* and plot the resulting PR curve.\n",
    "\n",
    "**You need to discuss your solution in person to receive these points.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
