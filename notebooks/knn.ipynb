{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b6c0166-20ca-4018-b2ee-3a7865d98e6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f82cb21767708a72ef5ed4e5ce27800",
     "grade": false,
     "grade_id": "cell-815a214cfd0b34d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# [1.1: KNN] // Collaborative Filtering with KNN\n",
    "\n",
    "## Context\n",
    "\n",
    "Services like Bol.com, Amazon, Facebook, Youtube, Instagram, Google, TikTok, and Netflix all try to predict which products (books, movies, videos, newspaper articles, or other items) you might be interested in. In this assignment, you will create a first version of such a prediction system, using a well know machine learning algorithm called **k-nearest neighbors** (KNN).\n",
    "\n",
    "These predictions are usually based on users’ behavior on a platform. Users view items, purchase them, give ratings, or mark things as favorites. All this information helps reveal the kind of products someone likes. Once we know this, we can look for similar products they have not seen yet and estimate whether they might enjoy them too.\n",
    "\n",
    "A common way to decide whether two items (e.g., two movies) are similar is to compare their content:\n",
    "\n",
    "* Are they about the same topic?\n",
    "* Do they feature the same actors?\n",
    "* Do they belong to the same genre?\n",
    "\n",
    "Recommending items based on these kinds of features is known as **content-based filtering**, which we will explore later.\n",
    "\n",
    "In this module, we focus on **collaborative filtering**. The key idea is that user behavior (ratings and interactions) contains information about both users *and* items.\n",
    "\n",
    "Collaborative filtering comes in two main forms:\n",
    "\n",
    "* **User-based filtering:** Find users who behave similarly and recommend items that those similar users liked.\n",
    "* **Item-based filtering:** Find items that receive similar ratings and recommend items that are similar to the ones a user already likes.\n",
    "\n",
    "Which approach works best, content-based, user-based collaborative filtering, or item-based collaborative filtering?\n",
    "There is no universal answer. The best choice depends strongly on the specific application and dataset.\n",
    "\n",
    "Each approach also involves design decisions that affect performance. For instance, we can measure similarity in many ways. A common choice is **Euclidean distance** and **cosine similarity**, but in practice even more options exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66639289-0604-4cad-abc7-e94fff8425cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "961a606f09ff78e47d80c52ad7ea018e",
     "grade": false,
     "grade_id": "cell-535dab2bf455578d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Study Material\n",
    "\n",
    "* **Video:** [Collaborative Filtering – Harvard CS50](https://www.youtube.com/watch?v=Eeg1DEeWUjA)\n",
    "* **Book:** *Recommender Systems: The Textbook* — Chapters 1 and 2\n",
    "  (Available as a free download via the UvA network.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d40d3-2af3-4312-9d19-2fee82bf1351",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d79afb2771e60d06a31910b648cf45c",
     "grade": false,
     "grade_id": "cell-3cc2aa297cef29c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Goal\n",
    "\n",
    "For this assignment, we will build a collaborative filtering system using a dataset from [MovieLens](http://movielens.org), a well-known movie recommendation platform. The dataset (will automatically be downloaded further down) consists of three CSV files:\n",
    "\n",
    "* `movies.csv`\n",
    "* `ratings.csv`\n",
    "* `tags.csv`\n",
    "\n",
    "CSV stands for *comma-separated values*, a common format for storing tabular data.\n",
    "\n",
    "Our goal is to use this dataset to recommend movies that a user has **not** watched yet. To do this, we look at the ratings a user has given to **other** movies and use that information to estimate how much they would enjoy a new movie.\n",
    "\n",
    "If we frame this as a prediction task:\n",
    "\n",
    "> **Given a user who has not seen a particular movie, predict the rating they would likely give after watching it.**\n",
    "\n",
    "This predicted rating will form the basis of our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b6d60-560c-4118-b924-686d25f42ab7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fc3b98457cc996402c14f0466e489f2",
     "grade": false,
     "grade_id": "cell-43da8eed0ed6130e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "### Libraries\n",
    "\n",
    "Let's start by loading the libraries we'll need by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf330fe5-c763-46d1-9c5f-07b285118a5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6ed55ca9a149b70928d4dfe0c12e73f",
     "grade": false,
     "grade_id": "cell-6c9b22e49746a226",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#provide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pooch\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b76bf2-53c0-4b62-b786-ad7c69b33a0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "709cb9ff6afcfade611de4d5d9796031",
     "grade": false,
     "grade_id": "cell-1002e87564e0616a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Download data\n",
    "\n",
    "Now download the required data and helper files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a81c32-43b8-4aec-bf8e-1e436d806044",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b604751fbdebbd1f153947cd676e1bb",
     "grade": false,
     "grade_id": "cell-4bf661af32788d42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# download data\n",
    "DATA_REPO = \"https://raw.githubusercontent.com/uvapl/recommender-systems/main/data/m1/\"\n",
    "\n",
    "print(\"downloading data files\")\n",
    "for fname in [\"movies.csv\", \"users.csv\", \"ratings.csv\"]:\n",
    "    pooch.retrieve(url = DATA_REPO + fname, known_hash=None, fname=fname, path=\"data\", progressbar=True)\n",
    "for fname in [\"helpers_m1.py\", \"cosine.png\", \"tests_m1.py\"]:\n",
    "    pooch.retrieve(url = DATA_REPO + fname, known_hash=None, fname=fname, path=\".\", progressbar=True)\n",
    "print(\"done!\")\n",
    "\n",
    "import helpers_m1\n",
    "import tests_m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e84a36-b933-4091-9836-c053353197c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "889c4244de9841551817038db8a47555",
     "grade": false,
     "grade_id": "cell-9d2936aa305b1f03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## User-based filtering using KNN\n",
    "\n",
    "Our goal is to recommend movies to a specific user. There are many approaches to this, but in this assignment we begin with **collaborative filtering**. The core idea behind collaborative filtering is to use user interactions (in this case, ratings from the MovieLens dataset) to guide our recommendations.\n",
    "\n",
    "In **user-based filtering**, we focus on finding users who behave similarly. The intuition is straightforward: if two users tend to give similar ratings to many of the same movies, they likely have similar taste. If one of these users watches and enjoys a movie that the other has not seen yet, that movie becomes a good candidate for a recommendation.\n",
    "\n",
    "To build a user-based filtering system, we will go through the following steps:\n",
    "\n",
    "1. **Reading the data**\n",
    "2. **Transforming the data into a usable format** (a utility matrix with users as rows and movies as columns)\n",
    "3. **Define similarities between users**\n",
    "4. **Using these similarities to make a recommendation (using KNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b97d60-060c-43c3-9a8f-db400c042f1e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac65570ea839d4dfdb5b3453d2219cd7",
     "grade": false,
     "grade_id": "cell-bcb8ed0ca45ee42d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Reading Data\n",
    "\n",
    "We'll start with a micro-dataset. This small set contains 3 movies and 30 users. It is a syntetic dataset similar in structure to the MovieLens dataset. This allows you to easily test your code since you have an overview of all the data. For comparison, the original dataset contains over 30 milion users. The algorithms we are going to apply should, in principle, also work on the full dataset, although it will be challenging to create solutions that are efficient enought to deal with those amounts of data.\n",
    "\n",
    "The dataset consists of 3 tables (which we will read as Pandas `DataFrame`s):\n",
    "- **movies**, a table with the movie's id, name, and genre.\n",
    "- **users**, a table with the user's id and name.\n",
    "- **ratings**, a table with the user's id, the movie's id, the corresponding rating, and the timestamp.\n",
    "\n",
    "In the following tasks, we will only use the ratings table. The other two tables are provided for our intuition and reasoning. It's easier to talk about Shrek than movie 4306, so please do so when asked about certain movies in open questions.\n",
    "\n",
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f00ed-e822-424c-bc05-f27c6e80c51a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f04fef47bc00d99b55726767248e16f",
     "grade": false,
     "grade_id": "cell-f762eba397d58a52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"data/movies.csv\", index_col=\"movieID\")\n",
    "df_users = pd.read_csv(\"data/users.csv\", index_col=\"userID\")\n",
    "df_ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "\n",
    "print(df_movies.head())\n",
    "print(df_users.head())\n",
    "print(df_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0030d9c9-ed3d-4748-ae29-f98e3969e363",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5223204e487e7588c6bf9005ce9d32f1",
     "grade": false,
     "grade_id": "cell-67fcc339c3267504",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Pivot\n",
    "\n",
    "To analyze the data, we first create a table that shows how each user rated each movie. A small example (the real table is much larger) might look like this:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\"><thead><tr style=\"text-align: right;\"><th>movieID</th><th>M1024</th><th>M2048</th><th>M4096</th></tr><tr><th>userID</th><th></th><th></th><th></th></tr></thead><tbody><tr><th>U025</th><td>7.9</td><td>7.0</td><td>10.0</td></tr><tr><th>U027</th><td>5.4</td><td>2.6</td><td>10.0</td></tr><tr><th>U030</th><td>7.0</td><td>6.2</td><td>10.0</td></tr><tr><th>U032</th><td>4.9</td><td>10.0</td><td>NaN</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td></tr></tbody></table>\n",
    "\n",
    "\n",
    "This table is called the **utility matrix**. It records which user rated which movie and with what score. For example, from the matrix we can immediately see that user `U027` (Sofia Garcia) gave a rating of `5.4` to movie `M1024` (Titanic).\n",
    "\n",
    "Because we are working on **user-based filtering**, we want to compare **users** with each other. The convention for this method is to put **users on the vertical axis**. Each row represents a user, and the columns correspond to the **features** of that user (in this case, their ratings for the available movies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182df1e-8070-4567-ab3a-355310211257",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2441442dc108d652be2a394718431679",
     "grade": false,
     "grade_id": "cell-bb03b507d2c61b68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "_2 pt._\n",
    "\n",
    "The function `pivot_ratings()` below is still incomplete. It should generate the utility matrix described above. You will implement this function yourself; this means you are **not** allowed to use pandas’ built-in `pivot()` function (yet).\n",
    "\n",
    "If there is no rating for a particular (user, movie) combination, the corresponding entry in the table should be `NaN`. You can use `np.nan` for this.\n",
    "\n",
    "* **Tip 1:** The tests expect the output of `pivot_ratings()` to be a pandas `DataFrame` with elements of type `float`. You can enforce this by using the argument `dtype=float` when creating the `DataFrame`.\n",
    "\n",
    "Implement `pivot_ratings()` below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7251561-64a7-48ee-9801-e87c554ae5b5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a60da803072a324aa5082ba3d331a763",
     "grade": false,
     "grade_id": "cell-a09933b154c2b084",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pivot_ratings(ratings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a rating table as input and computes the utility matrix using pandas pivot function.\n",
    "    Overwrites the pivot function from the previous exercise.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "\n",
    "\n",
    "df_utility = pivot_ratings(df_ratings)\n",
    "display(df_utility.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fb7af-51b7-4f25-b395-e814b834493f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66da263713086687ecc98fdba47246d8",
     "grade": true,
     "grade_id": "cell-0b747774ec71d0b5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "tests_m1.knn_01(pivot_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39912ef2-db4d-4572-9a4c-6e861242314f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64344e6d8c4cf61e758f501c9b456182",
     "grade": false,
     "grade_id": "cell-63cf8ce34b1b0862",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Plot\n",
    "\n",
    "Next, we want to visualize the ratings for two specific movies: **Frozen** and **Titanic**. The plot should help us see how users rated these movies relative to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffa8ac-67ca-4364-a379-1307e9999be1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49d96595d1cfbcef14aad585c1137d4e",
     "grade": false,
     "grade_id": "cell-08c724b70057fb59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "helpers_m1.plot_movie_data(df_utility, \"M1024\", \"M2048\", \"M4096\", {\"M1024\": \"Titanic\", \"M2048\": \"Frozen\", \"M4096\": \"Inception\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698249f9-6eed-47d1-86ea-843a918826de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ae2240ff0508c4428037903767de913",
     "grade": false,
     "grade_id": "cell-da93d8efce8d5736",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Mean-Centering\n",
    "\n",
    "In the scatterplot of **Frozen** versus **Titanic**, most points are clustered in the **upper-right corner**. This shows that many users rated *both* movies quite highly.\n",
    "\n",
    "At first glance, this suggests that these users have similar taste. However, the plot is misleading because **users have different rating habits**: some rate generously and give almost everything a 4 or 5, while others are stricter and rarely go above a 3. When the movies being compared are generally well-liked, these differences get hidden, and users appear more similar than they actually are.\n",
    "\n",
    "To correct this, we should not use the **absolute** ratings, but rather how each user rated the movie **relative to their own typical rating level**.\n",
    "\n",
    "**Mean-centering** does exactly that. By subtracting each user’s average rating from all their ratings, we obtain *relative* preferences that allow for more meaningful similarity comparisons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c78d67-2380-4efa-a5de-89f258dd079a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "807cd7b864ddc8b2e14b54e67369435a",
     "grade": false,
     "grade_id": "cell-ce29f24afddbcc8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "_2 pt._\n",
    "\n",
    "Implement the function `mean_center()` below. It should subtract each user’s average rating from all of their individual ratings. (If you are comfortable with pandas, this can be done in just one or two lines of code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415f2047-2698-419a-bae7-ce2462c7ebf8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14c0d260f3101dc079ee89dd97f3367c",
     "grade": false,
     "grade_id": "cell-59c263950e3eb4d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mean_center(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # your code here\n",
    "\n",
    "df_utility_mean_centered = mean_center(df_utility)\n",
    "display(df_utility_mean_centered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16776bef-7bd9-4f02-9ffd-9d2a57c4b63d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0966d5fcc38565d214c9f2619d71f55f",
     "grade": true,
     "grade_id": "cell-8ee251e7f7ca9cfa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "tests_m1.knn_02(mean_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb797fa-3103-494e-a4be-a036caeb59cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaefe736e18b9f1b264379e99c1274cc",
     "grade": false,
     "grade_id": "cell-caaf6860969dc5be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's plot the new DataFrame to see what the mean-centered data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e06908-af77-4e0a-bd57-8d75e7ee44de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc4b184747053010129c89fa92f096ec",
     "grade": false,
     "grade_id": "cell-499225055e5637db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "helpers_m1.plot_movie_data(df_utility_mean_centered, \"M1024\", \"M2048\", \"M4096\", {\"M1024\": \"Titanic\", \"M2048\": \"Frozen\", \"M4096\": \"Inception\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1352c0-b3e3-415a-8d0f-5ced125f2694",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f4b2579c6dd9dfde23457fe2dc140c6",
     "grade": false,
     "grade_id": "cell-6b4035d34b6b4a1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, the data is now much more spread out around the origin. This gives a much clearer view of the differences between data points. It also makes the **cosine similarity** (which we will use later when implementing kNN) behave much better and produce more meaningful similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642446d8-deda-4d4d-b99a-c685be5b36e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "192ff9956195bfca9e7f31146a9da2ec",
     "grade": false,
     "grade_id": "cell-79c358383ef708ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Split data\n",
    "\n",
    "Now we want to actually start recommending movies. In particular, we would like to know whether we can recommend the movie **`M4096` (Inception)** to users who have **not** rated it yet (specifically: **U758 - Tomáš Novák** and **U032 - Marta Nowak**).\n",
    "The first step is to **predict** what rating they *would* give Inception if they had seen it.\n",
    "\n",
    "Before we can make any predictions, we need to separate the data into two parts:\n",
    "\n",
    "* **X**: the input data (here: the ratings for movies `M1024` and `M2048`)\n",
    "* **y**: the target we want to predict (the ratings for `M4096`)\n",
    "\n",
    "Some users have a rating for `M4096`—these are the users we can learn from. Others do not—these are the users we want to predict for.\n",
    "The function `transform_data_for_knn()` will split the DataFrame accordingly:\n",
    "\n",
    "* **`X_known` and `y_known`** — users with a known rating for `M4096`\n",
    "* **`X_unknown` and `y_unknown`** — users with a missing rating for `M4096`\n",
    "\n",
    "Because kNN requires complete feature vectors, you must fill missing values in **X** using the column means.\n",
    "(Do **not** fill missing values in **y**; `y_unknown` should remain `NaN`.)\n",
    "\n",
    "After this step, only `y_unknown` contains `NaN` values—none of the other returned frames should.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e8ecd-c29a-4d98-83d2-1144ee382554",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1334615d63bdde36212391f137c02336",
     "grade": false,
     "grade_id": "cell-475997806fcd4c9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "_3 pt._\n",
    "\n",
    "Complete the function `transform_data_for_knn(df, X_cols, y_col)` so that it:\n",
    "\n",
    "1. Selects the feature columns `X_cols` and fills any `NaN` values with the column mean.\n",
    "2. Extracts the target column `y_col`.\n",
    "3. Splits the data further into four parts:\n",
    "\n",
    "   * `X_known`: the DataFrame containing the rows in X for which the corresponding y value is known\n",
    "   * `y_known`: the Series conatinaing the y values that are known\n",
    "   * `X_unknown`: the DataFrame containing the the rows in X for which the corresponding y value is missing\n",
    "   * `y_unknown`: the Series containing the y values that are missing (these should be `NaN`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059b3da-8d6a-4fff-afdb-25630004fe3f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "215399824c5854df3f663f07121ded67",
     "grade": false,
     "grade_id": "cell-d789dac14c4cfff3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_data_for_knn(df: pd.DataFrame, X_cols: list[str], y_col: str) -> tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    # your code here\n",
    "    \n",
    "\n",
    "X_known, y_known, X_unknown, y_unknown = transform_data_for_knn(df_utility_mean_centered, [\"M1024\", \"M2048\"], \"M4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f121eed-cf77-4f30-b28a-6446f42da80e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd5833de4f27638393c6bb592167b0d3",
     "grade": true,
     "grade_id": "cell-b0f940c1ef6fa1cf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "\n",
    "tests_m1.knn_03(transform_data_for_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e34fe2-47f6-49a0-af6b-ff60cbfafce2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5527145dd893db8ecd5a5af6529a625d",
     "grade": false,
     "grade_id": "cell-5062fdbb2fd21610",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Similarity\n",
    "\n",
    "### Manhattan Distance\n",
    "\n",
    "Previously, we looked at plots to get an intuitive feel for which users are similar. Now we will formalize this idea.\n",
    "\n",
    "Ultimately, we want a function that can quantify **how similar two users are** based on their ratings.\n",
    "\n",
    "First, we need a definition of **distance**. A simple starting point is to look at the differences between the ratings that two users gave. Consider the (mean-centered) ratings of users `U025` and `U027`:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "<thead>\n",
    "<tr style=\"text-align: right;\"><th>movieID</th><th>M1024</th><th>M2048</th></tr>\n",
    "<tr><th>userID</th><th></th><th></th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><th>U025</th><td>-0.4</td><td>-1.3</td></tr>\n",
    "<tr><th>U027</th><td>-0.6</td><td>-3.4</td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "We ignore movie `M4096`, because that is the movie we want to **predict** ratings for. When predicting the rating for a particular movie, it does not make sense to also use that same movie to compute similarities.\n",
    "\n",
    "The differences in their ratings are:\n",
    "\n",
    "* For `M1024`: $d_{M1024} = -0.4 - (-0.6) = 0.2$\n",
    "* For `M2048`: $d_{M2048} = -1.3 - (-3.4) = 2.1$\n",
    "\n",
    "We can now define the distance between these two users as the sum of the absolute values of these differences:\n",
    "\n",
    "$$\n",
    "d = |0.2| + |2.1| = 2.3\n",
    "$$\n",
    "\n",
    "This distance measure is called the **Manhattan distance** (see [Wikipedia:Taxicab Geometry](https://en.wikipedia.org/wiki/Taxicab_geometry) if you are curious about the name).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc747cee-d415-4d4b-92a8-525371375c88",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "454341b3e8a58c9871d70abdd761cd4c",
     "grade": false,
     "grade_id": "cell-aa1532a05c56b1a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### NaN-Values\n",
    "\n",
    "When computing similarities, it is essential that the data contains **no NaN values**. Consider the following example:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "<thead>\n",
    "<tr style=\"text-align: right;\"><th>movieID</th><th>M1024</th><th>M2048</th></tr>\n",
    "<tr><th>userID</th><th></th><th></th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><th>U025</th><td>-0.4</td><td>-1.3</td></tr>\n",
    "<tr><th>U027</th><td>-0.6</td><td><b>NaN</b></td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "If we compute the rating differences, the NaN immediately “contaminates” the calculation:\n",
    "\n",
    "* For `M2048`: $d_{M2048} = -1.3 - \\mathbf{NaN} = \\mathbf{NaN}$\n",
    "* $d = |0.2| + |\\mathbf{NaN}| = \\mathbf{NaN}$\n",
    "\n",
    "So the entire distance between the users becomes `NaN`, even though we *do* have at least one movie (`M1024`) that both users rated.\n",
    "\n",
    "In real datasets, missing values are unavoidable. If NaNs prevented us from computing distances, we would rarely be able to compute similarities at all.\n",
    "\n",
    "This is why we had to **fill the NaN values in the `X` DataFrame** (the feature data) in the previous assignment. Filling with the column mean ensures that kNN receives complete feature vectors and can compute meaningful similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07d254-fe61-4c2b-9c96-05919b3705a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f35183b85afe86808aae5c2e6bdd37f1",
     "grade": false,
     "grade_id": "cell-c56570647a8abdc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Cosine Similarity Intuition\n",
    "\n",
    "In practice, you would rarely use Manhattan distance. A more common alternative is **Euclidean distance**, which takes the square root of the sum of squared differences:\n",
    "\n",
    "$$\n",
    "d = \\sqrt{0.2^2 + 2.1^2} \\approx 2.11\n",
    "$$\n",
    "\n",
    "This is simply the Pythagorean distance between two points.\n",
    "\n",
    "However, in recommender systems the most widely used similarity measure is **cosine similarity**. To compute it, imagine drawing two vectors from the origin to the points we want to compare and then measuring the **angle** between those vectors:\n",
    "\n",
    "<img src='cosine.png' width=\"500pt\">\n",
    "\n",
    "In the example above, we compare users `U032` and `U432`, using only their ratings for movies `M1024` and `M2048`. They have the following scores:\n",
    "<table border=\"1\" class=\"dataframe\"><thead><tr style=\"text-align: right;\"><th>movieID</th><th>M1024</th><th>M2048</th></tr><tr><th>userID</th><th></th><th></th></tr></thead><tbody><tr><th>U032</th><td>-2.55</td><td>2.55</td></tr><tr><th>U432</th><td>-0.77</td><td>3.03</td></tr></tbody></table>\n",
    "\n",
    "The angle between the two vectors is approximately $30.95^\\circ$.\n",
    "Cosine similarity is defined as the **cosine** of that angle:\n",
    "\n",
    "$$\n",
    "\\cos(\\alpha) \\approx 0.859\n",
    "$$\n",
    "\n",
    "A key property of cosine similarity is that the **distance to the origin does not matter**, only the **direction** of the vector does. (Think about why this is useful when users have different rating habits.)\n",
    "\n",
    "Note that cosine similarity always produces a score between **1** and **–1**:\n",
    "\n",
    "* **1** means the vectors point in exactly the same direction (high similarity),\n",
    "* **–1** means they point in opposite directions (high dissimilarity).\n",
    "\n",
    "### Calculating Cosine Similarity\n",
    "\n",
    "Despite the geometric description, computing cosine similarity is straightforward. For two points\n",
    "($A = (a_1, a_2)$) and ($B = (b_1, b_2)$), we compute:\n",
    "\n",
    "$$\n",
    "\\cos(A,B) =\n",
    "\\frac{a_1 b_1 + a_2 b_2}\n",
    "{\\sqrt{a_1^2 + a_2^2},\\sqrt{b_1^2 + b_2^2}}\n",
    "$$\n",
    "\n",
    "In our specific example:\n",
    "\n",
    "$$\n",
    "\\cos(\\text{U032}, \\text{U432}) =\n",
    "\\frac{-2.55 \\cdot -0.77 + 2.55 \\cdot 3.03}\n",
    "{\\sqrt{(-2.55)^2 + 2.55^2},\\sqrt{(-0.77)^2 + 3.03^2}}\n",
    "\\approx 0.859\n",
    "$$\n",
    "\n",
    "Here we used only two features for illustration. In reality, each user has many features (ratings for many movies). The general formula for (n) features is:\n",
    "\n",
    "$$\n",
    "\\cos(A, B) =\n",
    "\\frac{a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n}\n",
    "{\\sqrt{a_1^2 + a_2^2 + \\cdots + a_n^2},\n",
    "\\sqrt{b_1^2 + b_2^2 + \\cdots + b_n^2}}\n",
    "$$\n",
    "\n",
    "Or, more formally, using sum notation:\n",
    "\n",
    "$$\n",
    "\\cos(A, B) =\n",
    "\\frac{\\displaystyle \\sum_{i=1}^n a_i b_i}\n",
    "{\\sqrt{\\displaystyle \\sum_{i=1}^n a_i^2};\n",
    "\\sqrt{\\displaystyle \\sum_{i=1}^n b_i^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f883aa9-88c0-420b-86b5-93dc715f7e30",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4734f9a28f3b949d9a151f4ad3d823cf",
     "grade": false,
     "grade_id": "cell-0c0ac4f2b0cb927e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "_3 pts._\n",
    "\n",
    "Use the formula above to implement the function `cosine_similarity_matrix(X1, X2)` below. It should compute the cosine similarity between **all** users in `X1` and **all** users in `X2`.\n",
    "\n",
    "When applied to `X_known` and `X_unknown`, the result should look something like this:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "<thead>\n",
    "<tr style=\"text-align: right;\"><th>userID</th><th>U032</th><th>U758</th></tr>\n",
    "<tr><th>userID</th><th></th><th></th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><th>U025</th><td>-4.678877e-01</td><td>4.678877e-01</td></tr>\n",
    "<tr><th>U027</th><td>-5.734623e-01</td><td>5.734623e-01</td></tr>\n",
    "<tr><th>U030</th><td>-3.328201e-01</td><td>3.328201e-01</td></tr>\n",
    "<tr><th>U089</th><td>2.631174e-01</td><td>-2.631174e-01</td></tr>\n",
    "<tr><th>U095</th><td>9.871575e-01</td><td>-9.871575e-01</td></tr>\n",
    "<tr><th>U104</th><td>9.251969e-01</td><td>-9.251969e-01</td></tr>\n",
    "<tr><th>U114</th><td>-2.237114e-17</td><td>2.904027e-16</td></tr>\n",
    "<tr><th>...</th><td>...</td><td>...</td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "* The **rows** represent the users from `X1` (in this example, `X_known`).\n",
    "* The **columns** represent the users from `X2` (here, `X_unknown`).\n",
    "* Each value is the **cosine similarity** between the corresponding pair of users.\n",
    "\n",
    "This DataFrame is called a **similarity matrix**. It allows us to easily look up similarity scores later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9931a-ace9-48ba-b9c2-2a265268de48",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "885d52eca9859ea8cb9f884a331ffb30",
     "grade": false,
     "grade_id": "cell-80f7a75c9f85baeb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(X1: pd.DataFrame, X2: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute cosine similarities between each test sample (rows of X_test)\n",
    "    and each train sample (rows of X_train). Both are DataFrames.\n",
    "    Returns a DataFrame of shape (len(X_test), len(X_train)).\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "similarity = cosine_similarity_matrix(X_known, X_unknown)\n",
    "display(similarity.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81d209-a8e2-48d8-917d-334a896a8c62",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4321069053c4b3581f85cccb36fac08d",
     "grade": true,
     "grade_id": "cell-304c7a86c2a22727",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "\n",
    "tests_m1.knn_04(cosine_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613ecf8-48c7-4727-9c29-3fff2fa5c924",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ab85e262264ce61293c58d2488a252b",
     "grade": false,
     "grade_id": "cell-167b676175fe85c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div style=\"border: 2px solid #444; padding: 10px; border-radius: 10px;\">\n",
    "\n",
    "### Intermezzo: Using Vector Operations\n",
    "\n",
    "In any machine learning algorithm, it is useful to think in terms of **vector** and **matrix** operations, for two main reasons:\n",
    "\n",
    "* They lead to cleaner (simpler) code.\n",
    "* Modern hardware (especially GPUs) is highly optimized for these operations.\n",
    "\n",
    "In later assignments, we will expect you to implement solutions using vector and matrix operations. For this assignment, that is not strictly required yet, but for full credit (and to get used to this way of thinking), youre can try to re-implement the cosine similarity using vector operations.\n",
    "\n",
    "Cosine similarity can be rewritten in terms of vector operations.\n",
    "\n",
    "Let (a) and (b) be vectors containing all scores for two particular users.\n",
    "(In our example above, (a) could be the vector for user `U032`: (a = (-2.55, 2.55)), and (b) could be the vector for user `U432`: (b = (-0.77, 3.03)).)\n",
    "\n",
    "The cosine similarity between these two vectors is defined as:\n",
    "\n",
    "$$\n",
    "\\cos(a,b) = \\frac{a \\cdot b}{\\lVert a \\rVert \\lVert b \\rVert}\n",
    "$$\n",
    "\n",
    "Recall:\n",
    "\n",
    "* The **dot product** of two vectors is defined as the sum of the products of their elements:\n",
    "  $$\n",
    "  a \\cdot b = a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n\n",
    "  $$\n",
    "\n",
    "* The **norm** (length) of a vector (a) is:\n",
    "  $$\n",
    "  \\lVert a \\rVert = \\sqrt{a \\cdot a}\n",
    "  $$\n",
    "\n",
    "Using these definitions, you should be able to derive that this vector definition of cosine similarity is equivalent to the earlier formula with sums and square roots over individual components.\n",
    "Try to work this out to check your understanding of the math.\n",
    "\n",
    "\n",
    "### Question 4b\n",
    "\n",
    "*3 pts.*\n",
    "\n",
    "**Only do this question if you are ahead of schedule. Otherwise, finish all other homework first and then return to this section if you still have time.**\n",
    "\n",
    "Re-implement the `cosine_similarity_matrix` function above, but now using **vector operations**, and verify that you obtain exactly the same results.\n",
    "\n",
    "Hint: if you have two Pandas `Series`, `s1` and `s2`, you can treat them as vectors and compute their dot product using:\n",
    "\n",
    "    result = s1 @ s2\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f359cc8-96fd-45f1-b2dc-07051652c201",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4efc1aa56c53c1720fb5f8a6f182a820",
     "grade": true,
     "grade_id": "cell-269d704e1162be66",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9204e-5e29-44bc-983e-b2ac92a4a222",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7b4ea7e9597194de76f2df9785f69d7",
     "grade": false,
     "grade_id": "cell-459dd904ee163ac0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## KNN Regression\n",
    "\n",
    "Now all pieces are in place, and it is time to actually implement **k-nearest neighbors (kNN) regression** yourself (without using scikit-learn). The goal is to predict the missing ratings (`y_unknown`) using the known ratings (`y_known`):\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>Unknown ratings Series<br>(<code>y_unknown</code>)<br><br>\n",
    "    <table border=\"0\">\n",
    "        <tbody>\n",
    "            <tr><th>U032</th><td>NaN</td></tr>\n",
    "            <tr><th>U758</th><td>NaN</td></tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</td>\n",
    "<td> ----> KNN ----> </td>\n",
    "<td>Predicted ratings Series<br>(<code>y_predicted</code>)<br><br>\n",
    "    <table border=\"0\">\n",
    "        <tbody>\n",
    "            <tr><th>U032</th><td>-0.565795</td></tr>\n",
    "            <tr><th>U758</th><td> 2.797070</td></tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "The algorithm works as follows:\n",
    "\n",
    "1. **Compute cosine similarities**\n",
    "   For every user we would like to make a prediction (rows of `X_unknown`), compute the cosine similarity with every training user (rows of `X_known`).\n",
    "   You already implemented `cosine_similarity_matrix` for this.\n",
    "\n",
    "2. **Loop over each unknown user (each row of `X_unknown`):**\n",
    "\n",
    "   * Look up the similarity scores for that user in the similarity matrix.\n",
    "   * Select the **k most similar** users (the k highest similarity values).\n",
    "   * For those neighbors, obtain:\n",
    "\n",
    "     * their **similarities** (from the similarity matrix), and\n",
    "     * their **known ratings** (from `y_known`).\n",
    "   * Compute a **weighted average** of their known ratings:\n",
    "\n",
    "     * the **values** are the known ratings,\n",
    "     * the **weights** are the similarities.\n",
    "\n",
    "3. **Return the predictions** as a `Series` indexed like `X_unknown` and named like `y_known`.\n",
    "\n",
    "### Weighted Average\n",
    "\n",
    "To compute the weighted average, you use the similarities as weights and the known ratings as values. For example:\n",
    "\n",
    "* The neighbors of `U032` are: `U654`, `U604`, and `U616`.\n",
    "* Their similarities with `U032` (from the similarity matrix):\n",
    "  ```\n",
    "  U654    0.999592\n",
    "  U604    0.994309\n",
    "  U616    0.993990\n",
    "  \n",
    "  ```\n",
    "* Their known ratings (from `y_known`):\n",
    "  ```\n",
    "  U654   -0.1\n",
    "  U604   -0.6\n",
    "  U616   -1.0\n",
    "  \n",
    "  ```\n",
    "\n",
    "* So the predicted rating for `U032` is the weighted average:\n",
    "\n",
    "$$\n",
    "\\text{predicted rating} =\n",
    "\\frac{-0.1 \\cdot 0.999592 + -0.6 \\cdot 0.994309 + -1.0 \\cdot 0.993990}\n",
    "{0.999592 + 0.994309 + 0.993990}\n",
    "\\approx -0.565795\n",
    "$$\n",
    "\n",
    "The general formula (with ($r_i$) the rating and ($s_i$) the similarity of neighbor ($i$)) is:\n",
    "\n",
    "$$\n",
    "\\text{predicted rating} =\n",
    "\\frac{\\sum_{i \\in \\text{neighborhood}} r_i \\cdot s_i}\n",
    "{\\sum_{i \\in \\text{neighborhood}} s_i}\n",
    "$$\n",
    "\n",
    "### Intuition\n",
    "\n",
    "* Cosine similarity tells us **how close two users’ rating patterns are**.\n",
    "* We use only the **k most similar** users to avoid noisy or irrelevant information.\n",
    "* More similar users receive **higher weight** in the prediction.\n",
    "* The resulting rating estimate reflects the behavior of the most relevant neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c7fc4-03a2-4d39-b0fd-7bc3eb45bc07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ed37b891044a8e213af233c0ab3f5f4",
     "grade": false,
     "grade_id": "cell-308c29189d133a10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "*8 pts.*\n",
    "\n",
    "Implement the `knn_regression` function here below. As input it gets the `X_known`, `y_known`, and `X_unknown` objects. It should a Pandas Series with predicted ratings for all users in `X_unknown`. The name of the Series should be the movie we are currently predicting (i.e., the name of `y_known`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57849bc9-2934-4766-84c3-142fd78cb04c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f6ddf2776b2ff63cbaf152da4629e0c",
     "grade": false,
     "grade_id": "cell-df50782ee2989b75",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def knn_regression(X_known: pd.DataFrame, y_known: pd.Series, X_unknown: pd.DataFrame, k: int = 3) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Pure pandas / numpy implementation of KNN regression with:\n",
    "        - cosine similarity\n",
    "        - k nearest neighbors\n",
    "        - distance(weights)=similarity weights\n",
    "    Returns a Pandas Series, indexed like X_unknown and named like y_known.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: compute cosine similarity matrix (call cosine_similarity_matrix())\n",
    "\n",
    "    # Step 2: for each user in X_unknown:\n",
    "\n",
    "        # get all similarities from the similarity matrix for this user\n",
    "\n",
    "        # take k highest similarities\n",
    "\n",
    "        # get the known ratings for these neighbor users\n",
    "\n",
    "        # compute weighted average of the ratings of all neighbors (use similarities themsleves as weights)\n",
    "\n",
    "    # Step 3: return predictions as Series with same index as X_unknown\n",
    "\n",
    "    # your code here\n",
    "\n",
    "\n",
    "predictions = knn_regression(X_known, y_known, X_unknown)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b22b9-53f1-4fb1-9f09-34ac0362cd78",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb2a6d518d38ef98dc71dd9d85d39177",
     "grade": true,
     "grade_id": "cell-94ed466cc7c8f792",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "\n",
    "tests_m1.knn_05(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff12ebb2-cccf-405f-a8b3-ca703b9a2369",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56cf7e831db6175aa5ab830474e61967",
     "grade": false,
     "grade_id": "cell-808527da51950771",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Recommend\n",
    "\n",
    "We now have predicted ratings for the users who have not seen the movie yet. But that is not the final step. A predicted rating is just a number, we still need to decide whether it is high enough to justify recommending the movie.\n",
    "\n",
    "To do that, we pick a threshold value (for example `2.0`): if the predicted rating is above the threshold, we recommend the movie; if not, we do not recommend it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d354bd-17e3-4728-a96b-7bbbb32140b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "894295aa4a87d23c57e52e882ae56325",
     "grade": false,
     "grade_id": "cell-5f02bebdb323f37b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 6\n",
    "\n",
    "*2 pts.*\n",
    "\n",
    "Implement the function `recommend()` below. It should take the predicted ratings and a threshold, and return a `Series` of boolean values indicating whether the movie should be recommended to each user. A value of `True` means the predicted rating is above the threshold; `False` means it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f2b06-87c3-461b-94a1-f6d02654012b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32876f3c744bf5e3fa58163e713612ed",
     "grade": false,
     "grade_id": "cell-288761933dc92cd1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recommend(predictions: pd.Series, threshold: float) -> pd.Series:\n",
    "    # your code here\n",
    "\n",
    "# find recommendations\n",
    "recommendations = recommend(predictions, 2)\n",
    "\n",
    "# display results\n",
    "movie_name = df_movies.loc[recommendations.name].iloc[0]\n",
    "for user_id, recommended in recommendations.items():\n",
    "    user_name = df_users.loc[user_id].iloc[0]\n",
    "    print(f\"For {user_name} we do {\"\" if recommended else \"not \"}recommend the movie {movie_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9aaf3-f323-4a93-a576-b658a27fdab4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "957b34346a00b8f3a213544dcf627287",
     "grade": true,
     "grade_id": "cell-028737eab079a7a7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "\n",
    "tests_m1.knn_06(recommend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5b494-5ad4-47d1-a52c-b34bb79b3761",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a874e383f5f013f0541660b239aa400",
     "grade": false,
     "grade_id": "cell-ab82fd545b00e3f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations, you have created your first recommender system! You used kNN, a classic machine learning algorithm, to generate predictions for users who have not yet rated a movie.\n",
    "\n",
    "But how do we know how well it performs? The predictions above look reasonable, but we still need a systematic way to evaluate the quality of the algorithm.\n",
    "That is exactly what we will explore in the next notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
